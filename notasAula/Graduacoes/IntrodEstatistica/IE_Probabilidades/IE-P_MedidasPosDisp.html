<!DOCTYPE html>
<html lang="pt-BR">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Introdução à estatística</title>
        
         <!-- Carrega o arquivo de estilos customizados -->
        <link rel="stylesheet" href="../../../../styles.css">
        <!-- Carrega o arquivo de configuração do MathJax -->
        <script src="../../../../mathjax-config.js"></script>
        <!-- Plugin TikZ do MathJax v3 -->
        <script src="https://cdn.jsdelivr.net/npm/mathjax-plugin-tex-tikz@0.10.2/tikz.js"></script>
        <!-- Plugin XyJax do MathJax v3 para \xymatrix (Xy-pic) -->
        <script src="https://cdn.jsdelivr.net/npm/mathjax-plugin-tex-xyjax@0.2.1/xyjax.js"></script>
        <!-- Biblioteca MathJax v3 -->
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
        <!-- Estilos de itens -->
        <link rel="stylesheet" type="text/css" href="../../../../itemParenteses.css" />
        <!-- Ambiente de teorema -->
        <link rel="stylesheet" type="text/css" href="../../../../ambTeor.css" />
        <!-- Plugin TikZ do MathJax v3 -->
        <script src="../../../../scripts.js"></script>
        <style>
            body{
                counter-reset: contTeor contProp contLema contCoro contObs contDef contExerc contExemplo contCap 2 contSec 4;
            }
        </style>
    </head>
    
    <body>
        <div style="text-align:center"><h1><a class="hifscor" href="../IntrodEstatistica.html">Introdução à estatística</a></h1></div> 
        <h2><a class="hifscor" href="IE_Probabilidades.html">Capítulo 2 - Probabilidades</a></h2>
        <h3>Seção 4 - Esperança e variância de uma variável aleatória</h3>
        
        <p class="def" id="def_esperaX">
            Seja \(X: \Omega \to \mathbb{R}\) uma variável aleatória. Definimos a <strong>esperança</strong> de \(X\) como
        </p>

        <div class="equationWrapper">
            <span class="math">
                \[
                    E(X) \coloneqq
                    \begin{cases}
                        \displaystyle\sum_{i=1}^{k} x_i f_X(x_i), & \text{se } X(\Omega) = \{x_1, \dots, x_k\}, \\[8pt]
                        \displaystyle\int_{-\infty}^{\infty} x f_X(x) \, dx, & \text{se } X \text{ é contínua}.
                    \end{cases}
                \]
            </span>
        </div>

        <p>
            onde \(f_X\) é a função de probabilidade ou a função densidade de probabilidade de \(X\), conforme o caso.
        <span class="fim"></span></p>
        
        <p>
            Antes de apresentarmos algumas propriedades da esperança, vamos a duas definições.
        </p>
        
        <p class="def" id="def_probCondVarDis">
            Sejam \(X\) e \(Y\) variáveis aleatórias discretas e \(x, y \in \bbR\). A <strong>probabilidade condicional</strong> de \((X = x)\) dado \((Y = y)\), denotado por \(P(X=x\mid Y=y)\), é definido como
            <div class="equationWrapper">
                <span class="math">
                    \[
                        P(X=x\mid Y=y) \coloneqq \left\{
                        \begin{array}{cr}
                            \dfrac{P\big((X = x) \cap (Y = y)\big)}{P(Y = y)}, & \text{se } P(Y = y) > 0, \\
                            P(X = x), & \text{se } P(Y = y) = 0.
                        \end{array}
                        \right.
                    \]
                </span><span class="fim"></span>
            </div>
        </p>
        
        <p class="def" id="def_probCondVarDis">
            Sejam \(X\) e \(Y\) variáveis aleatórias discretas. Dizemos que elas são <strong>independentes</strong> se, para todo \(x, y \in \bbR\), vale que
            <div class="equationWrapper">
                <span class="math">
                    \[
                        P\big((X = x) \cap (Y = y)\big) = P(X = x)P(Y = y).
                    \]
                </span><span class="fim"></span>
            </div>
        </p>
        
        <p>
            Vamos ver, agora, algumas propriedades da esperança.
        </p>
        
        <p class="prop" id="prop_espX">
            <ol class="alfa">
                <li>Seja \(\varphi: \bbR \to \bbR\) uma função contínua e \(X: \Omega \to \bbR\) uma variável aleatória. Então a variável aleatória \(\varphi(X): \Omega \to \bbR\), \(\omega \mapsto \varphi\big(X(\omega)\big)\) é tal que</li>
                <div class="equationWrapper">
                    <span class="math">
                        \[
                            E\big(\varphi(X)\big) =
                            \begin{cases}
                                \displaystyle\sum_{i=1}^{k} \varphi(x_i) f_X(x_i), & \text{se } X(\Omega) = \{x_1, \dots, x_k\}, \\[8pt]
                                \displaystyle\int_{-\infty}^{\infty} \varphi(x) f_X(x) \, dx, & \text{se } X \text{ é contínua}.
                            \end{cases}
                        \]
                    </span>
                </div>
                <li>Se \(X: \Omega \to \bbR\) é variável aleatória constate, isto é, se existe \(c \in \bbR\) tal que \(X(\Omega) = \{c\}\), então \(E(X) = c\).</li>
                <li>Se \(X\) e \(Y\) são variáveis aleatórias e \(a, b \in \bbR\), então \(E(aX + bY) = aE(X) + bE(Y)\).</li>
                <li>Se \(X\) e \(Y\) são variáveis aleatórias discretas independentes, então \(E(XY) = E(X)E(Y)\).<span class="fim"></span></li>
            </ol>
        </p>
        
        <details>
            <summary>Demonstração</summary>
            <div class="caixa">
                A SER FEITO!
            </div>
            <button class="buttonDetails" onclick="closeDetail(this.parentElement)">&#9650;</button>
            <br>
        </details>
        
        <p class="def" id="def_varianciaX">
            Seja \(X: \Omega \to \mathbb{R}\) uma variável aleatória. Definimos a <strong>variância</strong> de \(X\) como
        </p>

        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) \coloneqq E\Big(\big(X - E(X)\big)^{2}\Big).
                \]
            </span><span class="fim"></span>
        </div>
        
        <p>
            Das propriedades da esperança temos que 
        </p>
        
        <div class="equationWrapper">
            <span class="math" id="eq_var">
                \[
                    V(X) \coloneqq E\Big(\big(X - E(X)\big)^{2}\Big) = E\Big(X^{2} - 2E(x) + E(X)^{2}\Big) = E(X^{2}) - 2E(X)E(X) + E(X)^{2} = E(X^{2}) - E(X)^{2}.
                \]
            </span>
        </div>
        
        <p>
            Seja
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    \begin{array}{rcl}
                        \varphi:\; \bbR & \to & \bbR \\
                        x & \mapsto & \big(x - E(X)\big)^{2}
                    \end{array}
                \]
            </span>
        </div>
        
        <p>
            Da <a href=#prop_espX> Proposição 2.4.1</a>, temos que
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) \coloneqq
                    \begin{cases}
                        \displaystyle\sum_{i=1}^{k} \big(x_i - E(X)\big)^{2} f_X(x_i) = \displaystyle\sum_{i=1}^{k} x_i^{2}f_X(x_i) - E(X)^{2}, & \text{se } X(\Omega) = \{x_1, \dots, x_k\}, \\[8pt]
                        \displaystyle\int_{-\infty}^{\infty} \big(x - E(X)\big)^{2} f_X(x) \, dx = \displaystyle\int_{-\infty}^{\infty} x^{2} f_X(x) \, dx - E(X)^{2}, & \text{se } X \text{ é contínua}.
                    \end{cases}
                \]
            </span>
        </div>
        
        <p class="prop" id="prop_varX">
            <ol class="alfa">
                <li>Se \(X: \Omega \to \bbR\) é variável aleatória constate, isto é, se existe \(c \in \bbR\) tal que \(X(\Omega) = \{c\}\), então \(V(X) = 0\).</li>
                <li>Se \(X\) é uma variável aleatórial e \(a, b \in \bbR\), então \(V(aX + b) = a^{2}V(X)\).</li>
                <li>Se \(X\) e \(Y\) são variáveis aleatórias discretas independentes, então \(V(X + Y) = V(X) + V(Y)\).<span class="fim"></span></li>
            </ol>
        </p>
        
        <details>
            <summary>Demonstração</summary>
            <div class="caixa">
                A SER FEITO!
            </div>
            <button class="buttonDetails" onclick="closeDetail(this.parentElement)">&#9650;</button>
            <br>
        </details>
        
        <p class="exemplo" id="exem_EspVarUniDis">
            Suponha que \(X \sim U(\{x_{1}, \dots, x_{n}\})\) e sejam \(\mu\) e \(\sigma^{2}\) a média e a variância populacional de \(\{x_{1}, \dots, x_{n}\}\). Então
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    E(X) = \displaystyle\sum_{i=1}^{n} x_i f_{X}(x_{i}) = \displaystyle\sum_{i=1}^{n} x_i \dfrac{1}{n} = \mu 
                \]
            </span>
        </div>
        
        <p>
            e
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) = \displaystyle\sum_{i=1}^{k} \big(x_i^{2} - E(X)^{2}\big)f_{X}(x_{i}) = \sum_{i=1}^{k} \big(x_i^{2} - \mu^{2}\big)\dfrac{1}{n} = \sigma^{2}.
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarBern">
            Suponha que \(X \sim \text{Ber}(p)\). Então
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    \begin{array}{l}
                        E(X) = \displaystyle\sum_{i=1}^{n} x_i f_{X}(x_{i}) = 1\cdot f_{X}(1) + 0 \cdot f_{X}(0) = p, \\[5pt]
                        E(X^{2}) = \displaystyle\sum_{i=1}^{n} x_{i}^{2} f_{X}(x_{i}) = 1^{2}\cdot f_{X}(1) + 0^{2} \cdot f_{X}(0) = p
                    \end{array}
                \]
            </span>
        </div>
        
        <p>
            e
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) = E(X^{2}) - E(X) = p - p^{2} = p(1-p).
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarBin">
            Suponha que \(X \sim \text{b}(n+1,p)\). Para calcularmos a esperança de \(X\), vamos usar duas igualdades:
        </p>
        
        <ol class="alfa">
            <li> a igualdade abaixo pode ser verificada, usando a definição de \(\binom{n}{k}\). Pode-se também pensar que tal equação resulta da solução de escolher um time com \(k\) integrantes de um total de \(n\) pessoas, onde um dos integrantes do time é o goleiro: do lado esquerdo da igualdade abaixo escolhemos \(k\) dos \(n\), depois escolhemos \(1\) dos \(k\); do lado direito, escolhemos primeiro o goleiro, ou seja, \(1\) dos \(n\), depois escolhemos o restante do time, isto é, escolhemos \(k-1\) dos \(n-1\):
                <div class="equationWrapper">
                    <span class="math">
                        \[
                            k \binom{n}{k} = n \binom{n-1}{k-1}; \tag*{\((\ast)\)}
                        \]
                    </span>
                </div>
            </li>
            <li> a igualdade abaixo é consequência do teorema binomial, isto é, \((a+b)^{n-1} = \sum_{\ell=0}^{n-1}\binom{n-1}{\ell}a^{\ell}b^{n-1-\ell}\):
                <div class="equationWrapper">
                    <span class="math">
                        \[
                           \sum_{\ell=0}^{n-1} \binom{n-1}{\ell}p^{\ell}(1-p)^{n-1-\ell} = \big(p+(1-p)\big)^{n-1} = 1. \tag*{\((\ast\ast)\)}
                        \]
                    </span>
                </div>
            </li>
        </ol>
        
        Assim, a esperança de \(X\) é
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    E(X) = \displaystyle\sum_{i=1}^{n+1} x_i f_{X}(x_{i}) = \sum_{k=0}^{n} k \binom{n}{k}p^{k}(1-p)^{n-k} \overset{(\ast)}{=} \sum_{k=1}^{n} n \binom{n-1}{k-1}p^{k}(1-p)^{n-k} = np \sum_{k=1}^{n} \binom{n-1}{k-1}p^{k-1}(1-p)^{n-k} \overset{(\ell = k -1)}{=} np \sum_{\ell=0}^{n-1} \binom{n-1}{\ell}p^{\ell}(1-p)^{n-1-\ell} \overset{(\ast\ast)}{=} np\big(p+(1-p)\big)^{n-1} = np.
                \]
            </span>
        </div>
        
        <p>
            Agora, para calcular a variância, basta notar que \(X = X_{1} + \cdots + X_{n+1}\), onde \(X_{i} \sim \text{Ber}(p)\) são independentes entre si. Assim, 
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) = V(X_{1} + \cdots + X_{n+1}) = V(X_{1}) + \cdots + V(X_{n+1}) = \sum_{i=1}^{n+1}p(1-p) = (n+1)p(1-p).
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarGeom">
            Suponha que \(X \sim \text{Geom}(p)\). Sabendo que \(\sum_{i=1}^{\infty}iq^{i-1} = \frac{1}{(1-q)^{2}}\), temos que
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    E(X) = \displaystyle\sum_{i=1}^{\infty} x_i f_{X}(x_{i}) = \sum_{i=1}^{\infty} i p(1-p)^{i-1} = p\sum_{i=1}^{\infty} i(1-p)^{i-1} = \dfrac{p}{p^{2}} = \dfrac{1}{p}.
                \]
            </span>
        </div>
        
        <p>
            Para a variância, usando que \(\sum_{i=1}^{\infty}i^{2}q^{i-1} = \frac{1+q}{(1-q)^{3}}\), temos que \(E(X^{2}) = \frac{2-p}{p^{2}}\). Logo,
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) = E(X^{2}) - E(X)^{2} = \dfrac{2-p}{p^{2}} - \dfrac{1}{p^{2}} = \dfrac{1-p}{p^{2}}
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarPoisson">
            Seja \(X \sim \pi(\lambda)\). Então
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    E(X) = \displaystyle\sum_{i=1}^{\infty} x_i f_{X}(x_{i}) = \sum_{i=0}^{\infty} i e^{-\lambda}\dfrac{\lambda^{i}}{i!} = e^{-\lambda}\lambda\sum_{i=1}^{\infty} \dfrac{\lambda^{i-1}}{(i-1)!} = e^{-\lambda}\lambda\sum_{k=0}^{\infty} \dfrac{\lambda^{k}}{k!} = e^{-\lambda}\lambda e^{\lambda} = \lambda.
                \]
            </span>
        </div>
        
        <p>
            Pode-se mostrar que \(E(X^{2}) = \lambda^{2} + \lambda\), logo,
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    V(X) = E(X^{2}) - E(X)^{2} =  \lambda^{2} + \lambda - \lambda^{2} = \lambda.
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarUniCon">
            Seja \(X \sim U[a,b]\). Então
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    \begin{array}{l}
                        E(X) = \dfrac{a+b}{2}, \\[5pt]
                        V(X) = \dfrac{(b-a)^{2}}{12}.
                    \end{array}
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarExp">
            Seja \(X \sim \text{Exp}(\lambda)\). Então
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    \begin{array}{l}
                        E(X) = \dfrac{1}{\lambda}, \\[5pt]
                        V(X) = \dfrac{1}{\lambda^{2}}
                    \end{array}
                \]
            </span><span class="fim"></span>
        </div>
        
        <p class="exemplo" id="exem_EspVarNormal">
            Seja \(X \sim \mathcal{N}(\mu, \sigma^2)\). Então
        </p>
        
        <div class="equationWrapper">
            <span class="math">
                \[
                    \begin{array}{l}
                        E(X) = \mu, \\[5pt]
                        V(X) = \sigma^{2}.
                    \end{array}
                \]
            </span><span class="fim"></span>
        </div>
        
        <div>
            <a href="IE-P_ExemploDistr.html">
                <button class="button button1">Capítulo 2 - Seção 3 - Exemplos de distribuição</button>
            </a>
        </div>
        
        <div>
            <a href="../IE_InferenciaEst/IE_InferenciaEst.html">
                <button class="button button1">Capítulo 3 - Inferência estatística</button>
            </a>
        </div>
    </body>  
</html>

